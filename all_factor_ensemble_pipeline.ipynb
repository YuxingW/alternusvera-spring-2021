{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "all_factor_ensemble_pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YuxingW/alternusvera-spring-2021/blob/main/all_factor_ensemble_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF4Qh5xVqM4D"
      },
      "source": [
        "## CMPE 257 - MLSprings 2021 Cohort\n",
        "Objective: Detect fake news in political datasets using factors\n",
        "mircro factors <br />\n",
        "Team DataCorps - Yuxing Wang, Arun Talkad, Mayuri Lalwani\n",
        "\n",
        "## True-o-meter Pipeline\n",
        "\n",
        "Micorfactors for Factor - Sychology Utilities, Yuxing\n",
        "* Sentiment\n",
        "* Group confirmation\n",
        "* Opinion leader\n",
        "\n",
        "Micorfactors for Factor - Intent, Mayuri\n",
        "* Utterance\n",
        "* Speech\n",
        "* Sentiment\n",
        "\n",
        "Micorfactors for Factor -Incredibility, Arun\n",
        "* Incredibility\n",
        "\n",
        "Reference: \n",
        "* https://towardsai.net/p/nlp/sentiment-analysis-opinion-mining-with-python-nlp-tutorial-d1f173ca4e3c\n",
        "* https://github.com/towardsai/tutorials/tree/master/sentiment_analysis_tutorial\n",
        "* https://machinelearningmastery.com/stacking-ensemble-machine-learning-with-python/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PnmDlwC8eFK"
      },
      "source": [
        "## 1.Preparation\n",
        "* Scrape data from politifact\n",
        "* Fetch twitter tweets by APIs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCdKoergjmDw"
      },
      "source": [
        "###1.1.Scrape data from politifact"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLl8z7VEjpMw"
      },
      "source": [
        "!pip install -q beautifulsoup4\n",
        "!pip install -q vaderSentiment"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hBtFjjoqV2_"
      },
      "source": [
        "**Import Required Packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sSRIdY1HZCS",
        "outputId": "5b2f5f6b-ec08-48f1-ede4-73e8dd83d8a4"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import requests\n",
        "import string\n",
        "from string import punctuation\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from io import BytesIO\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIodWee7Erz8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "36235940-4f28-4914-c252-28d3b01b4090"
      },
      "source": [
        "def scrape_data_from_politifact(start=1, end=11):\n",
        "  url = \"https://www.politifact.com/issues/\"\n",
        "  issues = []\n",
        "  r = requests.get(url)\n",
        "  soup = BeautifulSoup(r.text,'html.parser')\n",
        "  results = soup.find_all('div', attrs={'class':'c-chyron__value'})\n",
        "  for result in results:\n",
        "    name = result.find('a').text\n",
        "    issue = result.find('a')['href'].replace(\"/\",\"\")\n",
        "    issues.append((name, issue))\n",
        "  url = \"https://www.politifact.com/factchecks/list/?page={pgno}&category={category}\"\n",
        "\n",
        "  records = []  \n",
        "\n",
        "  for i in range(start,end):\n",
        "    for issue, issue_url in issues[0:5]:\n",
        "      fUrl = url.format(pgno=str(i), category=issue_url)\n",
        "      r = requests.get(fUrl)\n",
        "      soup = BeautifulSoup(r.text, 'html.parser')  \n",
        "      results = soup.find_all('article', attrs={'class':'m-statement'})\n",
        "      for result in results:\n",
        "        date = result.find('footer',attrs={'class':'m-statement__footer'}).text.split(\"•\")[1].rstrip(\"\\n\")\n",
        "        reporter = result.find('footer',attrs={'class':'m-statement__footer'}).text.split(\"•\")[0].replace(\"\\nBy\",\"\")   \n",
        "        author = result.find('a',attrs={'class':'m-statement__name'}).text.replace(\"\\n\",\"\")\n",
        "        statement =  result.find('div', attrs = {'class':'m-statement__quote'}).find('a').text.replace(\"\\n\",\"\")\n",
        "        statement_descr = result.find('div', {'class':'m-statement__desc'}).text.replace(\"\\n\",\"\")\n",
        "        article_url =  result.find('a')['href']\n",
        "        verdict = result.find('img', attrs = {'class':'c-image__thumb'}, alt=True).attrs['alt']\n",
        "        records.append(( date, issue, reporter, author, statement, statement_descr, verdict, article_url))\n",
        "  return records\n",
        "\n",
        "records = scrape_data_from_politifact()\n",
        "df_politifact = pd.DataFrame(records,\n",
        "                         columns=['Date', 'Issue','Reporter','Author', 'Statement', 'Description', 'Verdict', 'Url'])  \n",
        "df_politifact.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Issue</th>\n",
              "      <th>Reporter</th>\n",
              "      <th>Author</th>\n",
              "      <th>Statement</th>\n",
              "      <th>Description</th>\n",
              "      <th>Verdict</th>\n",
              "      <th>Url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>May 7, 2021</td>\n",
              "      <td>Abortion</td>\n",
              "      <td>Bill McCarthy</td>\n",
              "      <td>Facebook posts</td>\n",
              "      <td>Says Chelsea Clinton tweeted, \"If Jesus were a...</td>\n",
              "      <td>stated on May 7, 2021 in a Facebook post:</td>\n",
              "      <td>pants-fire</td>\n",
              "      <td>/personalities/facebook-posts/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>March 31, 2021</td>\n",
              "      <td>Abortion</td>\n",
              "      <td>Tom Kertscher</td>\n",
              "      <td>Facebook posts</td>\n",
              "      <td>“Joe Biden puts pro-life groups on domestic ex...</td>\n",
              "      <td>stated on March 29, 2021 in a Facebook post:</td>\n",
              "      <td>barely-true</td>\n",
              "      <td>/personalities/facebook-posts/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>February 12, 2021</td>\n",
              "      <td>Abortion</td>\n",
              "      <td>Brandon Mulder</td>\n",
              "      <td>Greg Abbott</td>\n",
              "      <td>“Innocent lives will be saved” by ending taxpa...</td>\n",
              "      <td>stated on January 24, 2021 in a tweet:</td>\n",
              "      <td>false</td>\n",
              "      <td>/personalities/greg-abbott/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>November 18, 2020</td>\n",
              "      <td>Abortion</td>\n",
              "      <td>Noah Y. Kim</td>\n",
              "      <td>Facebook posts</td>\n",
              "      <td>There is “aborted male fetus” in the Oxford-As...</td>\n",
              "      <td>stated on November 15, 2020 in a Facebook post:</td>\n",
              "      <td>false</td>\n",
              "      <td>/personalities/facebook-posts/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>October 14, 2020</td>\n",
              "      <td>Abortion</td>\n",
              "      <td>Tom Kertscher</td>\n",
              "      <td>Tommy Tuberville</td>\n",
              "      <td>Says Doug Jones \"has voted to spend our tax do...</td>\n",
              "      <td>stated on October 8, 2020 in an ad:</td>\n",
              "      <td>false</td>\n",
              "      <td>/personalities/tommy-tuberville/</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Date     Issue  ...      Verdict                               Url\n",
              "0         May 7, 2021  Abortion  ...   pants-fire    /personalities/facebook-posts/\n",
              "1      March 31, 2021  Abortion  ...  barely-true    /personalities/facebook-posts/\n",
              "2   February 12, 2021  Abortion  ...        false       /personalities/greg-abbott/\n",
              "3   November 18, 2020  Abortion  ...        false    /personalities/facebook-posts/\n",
              "4    October 14, 2020  Abortion  ...        false  /personalities/tommy-tuberville/\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IluA4FssCwz"
      },
      "source": [
        "###1.2.Define callables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvi7pt-d5R6E"
      },
      "source": [
        "def get_text_processing(text):\n",
        "    stop_words = stopwords.words('english')\n",
        "    stop_words.append(['breaking', 'BREAKING'])\n",
        "    no_punctuation = [char for char in text if char not in string.punctuation]\n",
        "    no_punctuation = ''.join(no_punctuation)\n",
        "    return ' '.join([word for word in no_punctuation.split() if word.lower() not in stop_words])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glvtjoNpu4ir"
      },
      "source": [
        "def positive_to_num(_df, micfactor):\n",
        "  if _df[micfactor][0] in ['Positive', 'Negative'] :\n",
        "    _df[micfactor] = _df[micfactor].apply(lambda x: 1 if x == 'Positive' else 0)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55CcQYeeMt7m"
      },
      "source": [
        "##2.All Microfactors Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6JXxaedfOj7"
      },
      "source": [
        "!pip install -U -q pyDrive"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWqJQotGeV6b"
      },
      "source": [
        "# Import packages for google drive, auth\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "gdrive = GoogleDrive(gauth)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cl2CvPLQVJJU"
      },
      "source": [
        "###2.1.Define a all microfactors dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvmsElVqVSPJ"
      },
      "source": [
        "MICROFACTORS ={\n",
        "    'Sentiment': {\n",
        "        'pickle_id': '1eZ0TycVjHAyaFh8eKDmyLiQ_DN8rOcbI',},\n",
        "    'Sensationalism': {\n",
        "        'pickle_id': '1XEYOqUEkI52tW7ZWtIGRq0Qe5dOd2I_S',},              \n",
        "    'Clickbait': {\n",
        "        'pickle_id': '1pgSrMJD0m_7Cd1fg1xoZEN2P_CjnpUkb',},\n",
        "    'Confirmation': {\n",
        "        'pickle_id': '1v4M0PuGBxhAuxSC0gghXG56IJ_lpj1_-',\n",
        "        'callable': positive_to_num},\n",
        "    'OpinionLeader': {\n",
        "        'pickle_id': '1-FSuhaFUQ5RXQb8ehgxa3fLhct6RH6Xn',},\n",
        "    'Sentiment': {\n",
        "        'pickle_id': '1lmskvpX4VA4srCbjeN3x82PLwckgKfyE',},\n",
        "    'Speech': {\n",
        "        'pickle_id': '1wSbIsic1fw0tzyqpxsmpKV5XV-QkxYdz',},\n",
        "    'Utterance': {\n",
        "        'pickle_id': '1GKrJgg-UfLobb5DuYe1JkCXUtL3sdg0T',}, \n",
        "    }\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHo7uG_B21GU"
      },
      "source": [
        "###2.2.Load the pickled models for microfactors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ywq-gR921WD"
      },
      "source": [
        "import joblib, pickle\n",
        "\n",
        "microfactor_list = MICROFACTORS.keys()\n",
        "\n",
        "def generate_micrafactor_from_pickles(df):\n",
        "  # load pickle function\n",
        "  def load_pickle(file_id, microfactor):\n",
        "      downloaded = gdrive.CreateFile({'id': file_id})\n",
        "      downloaded.GetContentFile(microfactor + '.pkl')\n",
        "      pickle_filepath = '/content/{}.pkl'.format(microfactor)\n",
        "      try:\n",
        "        model = pickle.load(open(pickle_filepath, 'rb'))\n",
        "      except:\n",
        "        model = joblib.load(open(pickle_filepath, 'rb'))\n",
        "      return model;\n",
        "\n",
        "  # Preprocessing\n",
        "  df['Statement'] = df['Statement'].apply(get_text_processing)\n",
        "  statement = df['Statement'].to_numpy()\n",
        "  \n",
        "  for microfactor in microfactor_list:\n",
        "    print('generating microfactor :', microfactor)\n",
        "    # load microfactor pickle\n",
        "    microfactor_model = load_pickle(MICROFACTORS[microfactor]['pickle_id'],\n",
        "                                    microfactor)\n",
        "    # create new microfact column\n",
        "    try:\n",
        "      df[microfactor]  = microfactor_model.predict_proba(statement)[0]\n",
        "      print('predict_proba run normally')\n",
        "    except:\n",
        "      df[microfactor]  = microfactor_model.predict(statement)\n",
        "      if df[microfactor][0] in ['Positive', 'Negative'] :\n",
        "        df[microfactor] = df[microfactor].apply(lambda x: 1 if x == 'Positive' else 0)\n",
        "    \n",
        "    if 'callable' in MICROFACTORS[microfactor]:\n",
        "      MICROFACTORS[microfactor]['callable'](df, microfactor)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aH-A65lYqycQ"
      },
      "source": [
        "**Use politicfact dataset to generate microfactors and train Verdict**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omfvnRMjGdH3",
        "outputId": "ac0af175-7e96-4870-d04c-e5fb3f2c2301"
      },
      "source": [
        "df = df_politifact.copy()\n",
        "generate_micrafactor_from_pickles(df)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "generating microfactor : Sentiment\n",
            "generating microfactor : Sensationalism\n",
            "generating microfactor : Clickbait\n",
            "generating microfactor : Confirmation\n",
            "generating microfactor : OpinionLeader\n",
            "generating microfactor : Speech\n",
            "generating microfactor : Utterance\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "Qs5w1lVTihrS",
        "outputId": "4c2b91f9-24de-4190-da46-b143e90dfa4d"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Issue</th>\n",
              "      <th>Reporter</th>\n",
              "      <th>Author</th>\n",
              "      <th>Statement</th>\n",
              "      <th>Description</th>\n",
              "      <th>Verdict</th>\n",
              "      <th>Url</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Sensationalism</th>\n",
              "      <th>Clickbait</th>\n",
              "      <th>Confirmation</th>\n",
              "      <th>OpinionLeader</th>\n",
              "      <th>Speech</th>\n",
              "      <th>Utterance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>May 7, 2021</td>\n",
              "      <td>Abortion</td>\n",
              "      <td>Bill McCarthy</td>\n",
              "      <td>Facebook posts</td>\n",
              "      <td>Says Chelsea Clinton tweeted Jesus alive today...</td>\n",
              "      <td>stated on May 7, 2021 in a Facebook post:</td>\n",
              "      <td>pants-fire</td>\n",
              "      <td>/personalities/facebook-posts/</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>March 31, 2021</td>\n",
              "      <td>Abortion</td>\n",
              "      <td>Tom Kertscher</td>\n",
              "      <td>Facebook posts</td>\n",
              "      <td>“Joe Biden puts prolife groups domestic extrem...</td>\n",
              "      <td>stated on March 29, 2021 in a Facebook post:</td>\n",
              "      <td>barely-true</td>\n",
              "      <td>/personalities/facebook-posts/</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>February 12, 2021</td>\n",
              "      <td>Abortion</td>\n",
              "      <td>Brandon Mulder</td>\n",
              "      <td>Greg Abbott</td>\n",
              "      <td>“Innocent lives saved” ending taxpayer funding...</td>\n",
              "      <td>stated on January 24, 2021 in a tweet:</td>\n",
              "      <td>false</td>\n",
              "      <td>/personalities/greg-abbott/</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>November 18, 2020</td>\n",
              "      <td>Abortion</td>\n",
              "      <td>Noah Y. Kim</td>\n",
              "      <td>Facebook posts</td>\n",
              "      <td>“aborted male fetus” OxfordAstraZeneca “Covid ...</td>\n",
              "      <td>stated on November 15, 2020 in a Facebook post:</td>\n",
              "      <td>false</td>\n",
              "      <td>/personalities/facebook-posts/</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>October 14, 2020</td>\n",
              "      <td>Abortion</td>\n",
              "      <td>Tom Kertscher</td>\n",
              "      <td>Tommy Tuberville</td>\n",
              "      <td>Says Doug Jones voted spend tax dollars latete...</td>\n",
              "      <td>stated on October 8, 2020 in an ad:</td>\n",
              "      <td>false</td>\n",
              "      <td>/personalities/tommy-tuberville/</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Date     Issue  ... Speech Utterance\n",
              "0         May 7, 2021  Abortion  ...      0         1\n",
              "1      March 31, 2021  Abortion  ...      0         1\n",
              "2   February 12, 2021  Abortion  ...      0         1\n",
              "3   November 18, 2020  Abortion  ...      0         1\n",
              "4    October 14, 2020  Abortion  ...      0         1\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jl3I183lRr40"
      },
      "source": [
        "## 3.true-o-meter Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R586EHFw3LSB"
      },
      "source": [
        "###3.1. Ensemble a multilabel classification pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIxVGNHcrtj-"
      },
      "source": [
        "**Use ensembled model and microfactors to train Verdict, model will be pickled in data_to_pipeline processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyOowx3oNL_Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceb1a4d1-3ce7-45d9-fefb-cb3dfe0607d8"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "import joblib\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('standardscaler', StandardScaler()),\n",
        "    ('svm', SVC(C=1, probability=True))\n",
        "])\n",
        "\n",
        "def data_to_pipeline(df, _source=None, _target=None):\n",
        "  # Split data for training and validation\n",
        "  X, y = df[_source].values, df[_target].values\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42) \n",
        "  \n",
        "  # Training and prediction\n",
        "  pipeline.fit(X_train, y_train)\n",
        "  scores = cross_val_score(pipeline, X_test, y_test, cv=3)\n",
        "  print('now using %s to predict %s' % (_source, _target))\n",
        "  print('cross validation scores:', scores)\n",
        "  print('prediction score:', pipeline.score(X_test, y_test))\n",
        "\n",
        "  # Save the pickle file\n",
        "  pickle_filepath = '/content/' + _target + '_pipeline.pkl'\n",
        "  joblib.dump(pipeline, pickle_filepath)\n",
        "  print('pickle file is created:', pickle_filepath)\n",
        "  print('\\n')\n",
        "\n",
        "data_to_pipeline(df, _source = microfactor_list, _target = 'Verdict')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "now using dict_keys(['Sentiment', 'Sensationalism', 'Clickbait', 'Confirmation', 'OpinionLeader', 'Speech', 'Utterance']) to predict Verdict\n",
            "cross validation scores: [0.25490196 0.16       0.24      ]\n",
            "prediction score: 0.2251655629139073\n",
            "pickle file is created: /content/Verdict_pipeline.pkl\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttbvMNqL2_JW"
      },
      "source": [
        "###3.2.Automated Inference Pipeline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCP-VhCzReE3"
      },
      "source": [
        "**Load pickled true-o-meter pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBuqNrU6RffR"
      },
      "source": [
        "pickle_filepath = '/content/Verdict_pipeline.pkl'\n",
        "o_meter_model = joblib.load(open(pickle_filepath, 'rb'))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1WuitA3qCib"
      },
      "source": [
        "**Read a new piece of data from politifact**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os7X1gZy3KWK"
      },
      "source": [
        "records = scrape_data_from_politifact(start=12, end=13)\n",
        "df = pd.DataFrame(records, columns=['Date', 'Issue','Reporter','Author', 'Statement', 'Description', 'Verdict', 'Url'])  "
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjxtC2m5p4F0"
      },
      "source": [
        "**Predict and compare the Verdict**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6C89fTR5p4SK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "582b9894-b2a5-4196-c87c-9a14dda3f647"
      },
      "source": [
        "generate_micrafactor_from_pickles(df)\n",
        "df['pred_verdict'] = o_meter_model.predict(df[microfactor_list])\n",
        "df_intestest = df[['Statement', 'Verdict', 'pred_verdict']]\n",
        "df_intestest.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "generating microfactor : Sentiment\n",
            "generating microfactor : Sensationalism\n",
            "generating microfactor : Clickbait\n",
            "generating microfactor : Confirmation\n",
            "generating microfactor : OpinionLeader\n",
            "generating microfactor : Speech\n",
            "generating microfactor : Utterance\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Statement</th>\n",
              "      <th>Verdict</th>\n",
              "      <th>pred_verdict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Central Health hospital district Texas spends ...</td>\n",
              "      <td>true</td>\n",
              "      <td>false</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>US Government Accountability Office report say...</td>\n",
              "      <td>pants-fire</td>\n",
              "      <td>false</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Studies shown absence federal reproductive hea...</td>\n",
              "      <td>half-true</td>\n",
              "      <td>false</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Says bill HB 97 would prevent use taxpayer dol...</td>\n",
              "      <td>false</td>\n",
              "      <td>false</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>child born prematurely according president wor...</td>\n",
              "      <td>pants-fire</td>\n",
              "      <td>false</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Statement     Verdict pred_verdict\n",
              "0  Central Health hospital district Texas spends ...        true        false\n",
              "1  US Government Accountability Office report say...  pants-fire        false\n",
              "2  Studies shown absence federal reproductive hea...   half-true        false\n",
              "3  Says bill HB 97 would prevent use taxpayer dol...       false        false\n",
              "4  child born prematurely according president wor...  pants-fire        false"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06XERzqKkEql"
      },
      "source": [
        "df['verdict_norm'] = df['Verdict'].apply(lambda x: 'True' if x in ['true', 'mostly-true'] else 'False')\n",
        "df['pred_verdict_norm'] = df['pred_verdict'].apply(lambda x: 'True' if x in ['true', 'mostly-true'] else 'False')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JM2RnRfunKyy",
        "outputId": "318c7175-4a3f-4809-ae0e-d1e3c3191f6f"
      },
      "source": [
        "num_of_equals = 0\n",
        "num_of_diffs = 0\n",
        "for index, x in df.iterrows():\n",
        "  if x['verdict_norm'] == x['pred_verdict_norm']:\n",
        "    num_of_equals = num_of_equals + 1\n",
        "  else:\n",
        "    num_of_diffs = num_of_diffs +1\n",
        "\n",
        "print('num_of_equals: %s, num_of_diffs: %s' % (num_of_equals, num_of_diffs))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num_of_equals: 17, num_of_diffs: 13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1HaiWG4N79K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e1ec553-2c79-44ad-acc2-16c12fc124dd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "! cp /content/*.pkl /content/drive/MyDrive/pickles_nlp/"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnPPwKI89HPH",
        "outputId": "d8a2c37c-2339-4832-dd73-a295195c38cf"
      },
      "source": [
        "! ls /content/*.pkl "
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Clickbait.pkl\t\t  /content/Sensationalism.pkl\n",
            "/content/Confirmation.pkl\t  /content/Sentiment.pkl\n",
            "/content/Intent.pkl\t\t  /content/Speech.pkl\n",
            "/content/OpinionLeader.pkl\t  /content/Utterance.pkl\n",
            "/content/PsychologyUtilities.pkl  /content/Verdict_pipeline.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}